{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from evaluation_reg import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, roc_curve, precision_score, f1_score,make_scorer\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": "my_data = pd.read_csv('MAD_dataset_12.csv')",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(371782, 1684)\n"
     ]
    }
   ],
   "source": [
    "print(my_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "df_0 = my_data[my_data.iloc[:,1] == 0]\n",
    "df_1 = my_data[my_data.iloc[:,1] == 1]\n",
    "#n_samples_per_class = round((len(my_data[my_data.iloc[:,1] == 1])))\n",
    "n_samples_per_class = round((len(my_data[my_data.iloc[:,1] == 1])/10)*9)\n",
    "train_0 = df_0.sample(n=n_samples_per_class, random_state=42)\n",
    "train_1 = df_1.sample(n=n_samples_per_class, random_state=42)\n",
    "train = pd.concat([train_0, train_1])\n",
    "test = my_data.drop(train.index)\n",
    "X_train = train.iloc[:, 2:]\n",
    "y_train = train.iloc[:, 1]\n",
    "X_test = test.iloc[:, 2:]\n",
    "y_test = test.iloc[:, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.len = X.shape[0]\n",
    "        self.x_data = torch.from_numpy(X.values)\n",
    "        self.y_data = torch.from_numpy(y.values)\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index],self.y_data[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "train_dataset = DiabetesDataset(X_train,y_train)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=128,shuffle=True,num_workers=2,drop_last=True)\n",
    "test_dataset = DiabetesDataset(X_test,y_test)\n",
    "test_loader = DataLoader(dataset=test_dataset,batch_size=128,shuffle=True,num_workers=2,drop_last=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class GlycoproteinProphet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlycoproteinProphet, self).__init__()\n",
    "        self.prot_fc1 = nn.Linear(1280, 64)\n",
    "        self.prot_fc2 = nn.Linear(64, 32)\n",
    "        self.prot_dropout1 = nn.Dropout(0.3)\n",
    "        self.prot_dropout2 = nn.Dropout(0.2)\n",
    "        self.bn_prot1 = nn.BatchNorm1d(64)\n",
    "        self.bn_prot2 = nn.BatchNorm1d(32)\n",
    "        self.activation_fn = nn.GELU()\n",
    "        self.glycan_fc1 = nn.Linear(402, 64)\n",
    "        self.glycan_lstm = nn.LSTM(128, 64, 2, batch_first=True)\n",
    "        self.conv1 = nn.Conv1d(128, 64, 1)\n",
    "        self.glycan_rnn = nn.RNN(64, 64, 2)\n",
    "        self.glycan_f2 = nn.Linear(402, 32)\n",
    "        self.bn_glycan1 = nn.BatchNorm1d(32)\n",
    "\n",
    "        #self.bn_fc1 = nn.Linear(64, 32)\n",
    "        #medthod1\n",
    "        self.bn_fc1 = nn.Linear(64, 32)\n",
    "        self.bn_fc2 = nn.Linear(32, 16)\n",
    "        self.bn_fc3 = nn.Linear(16, 1)\n",
    "        self.bn_relu = nn.ReLU()\n",
    "        # Attention\n",
    "\n",
    "        self.W_query = nn.Linear(402, 64)\n",
    "        self.W_key = nn.Linear(402, 64)\n",
    "        self.W_value = nn.Linear(402, 64)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.attention_glycan_fc1 = nn.Linear(466, 32)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        prot_X_train_tensor = input[:, 0:1280].to(device)\n",
    "        glycan_X_train_tensor = input[:, 1280:1684].to(device)\n",
    "        prot_X_train_tensor = prot_X_train_tensor.float()\n",
    "        glycan_X_train_tensor = glycan_X_train_tensor.float()\n",
    "        x = self.prot_fc1(prot_X_train_tensor)\n",
    "        prot1 = self.bn_prot1(self.prot_dropout1(x))\n",
    "        prot2 = self.bn_prot2(self.prot_dropout2(self.prot_fc2(prot1)))\n",
    "       \n",
    "        # Attention\n",
    "        query = self.W_query(glycan_X_train_tensor)\n",
    "        key = self.W_key(glycan_X_train_tensor)\n",
    "        value = self.W_value(glycan_X_train_tensor)\n",
    "        key = key.transpose(0, 1)\n",
    "        scores = torch.matmul(query, key)\n",
    "        # attention_weights = torch.exp(scores)/torch.sum(scores, dim=1, keepdim=True)\n",
    "        # attention_weights = self.softmax(scores)\n",
    "        attention_weights = F.normalize(scores, p=2, dim=1)\n",
    "        weighted_values = torch.matmul(attention_weights, value)\n",
    "        #print(weighted_values.shape)\n",
    "        glycan_feature = torch.cat((glycan_X_train_tensor, weighted_values), dim=1)\n",
    "        glycan = self.attention_glycan_fc1(glycan_feature)\n",
    "        #glycan = self.glycan_f2(glycan_X_train_tensor)\n",
    "        h_n = torch.cat((prot2, glycan), 1)\n",
    "        #x = F.sigmoid(self.bn_fc1(h_n))\n",
    "        x = F.sigmoid(self.bn_fc3(self.bn_relu(self.bn_fc2(self.bn_relu(self.bn_fc1(h_n))))))\n",
    "        #x = nn.functional.softmax(self.bn_fc3(self.bn_relu(self.bn_fc2(self.bn_relu(self.bn_fc1(h_n))))))\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "GlycoproteinProphet = GlycoproteinProphet().to(device)\n",
    "# 定义损失函数和优化\n",
    "criterion = nn.BCELoss().to(device)\n",
    "#criterion = nn.CrossEntropyLoss().to(device)\n",
    "#criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.Adam(GlycoproteinProphet.parameters(), lr=0.001)\n",
    "\n",
    "# 学习率调度器\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "# 保存每个epoch的训练损失和验证损失\n",
    "\n",
    "\n",
    "num_epochs = 200"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: 0.3537\n",
      "Epoch [20/200], Loss: 0.3286\n",
      "Epoch [30/200], Loss: 0.3144\n",
      "Epoch [40/200], Loss: 0.3063\n",
      "Epoch [50/200], Loss: 0.2998\n",
      "Epoch [60/200], Loss: 0.2941\n",
      "Epoch [70/200], Loss: 0.2885\n",
      "Epoch [80/200], Loss: 0.2834\n",
      "Epoch [90/200], Loss: 0.2804\n",
      "Epoch [100/200], Loss: 0.2764\n",
      "Epoch [110/200], Loss: 0.2741\n",
      "Epoch [120/200], Loss: 0.2711\n",
      "Epoch [130/200], Loss: 0.2694\n",
      "Epoch [140/200], Loss: 0.2660\n",
      "Epoch [150/200], Loss: 0.2630\n",
      "Epoch [160/200], Loss: 0.2620\n",
      "Epoch [170/200], Loss: 0.2605\n",
      "Epoch [180/200], Loss: 0.2583\n",
      "Epoch [190/200], Loss: 0.2563\n",
      "Epoch [200/200], Loss: 0.2548\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_losses = []\n",
    "    #train_pred = []\n",
    "    #train_labels = []\n",
    "    GlycoproteinProphet.train().to(device)\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs,lables = data\n",
    "        lables = lables.float().to(device)\n",
    "        #lables = lables.type(torch.long).to(device)\n",
    "        #lables = lables.to(device)\n",
    "        #print(glycan_X_train_tensor.shape)\n",
    "        outputs= GlycoproteinProphet(inputs).squeeze().to(device)\n",
    "        #print(outputs)\n",
    "        loss = criterion(outputs, lables).to(device)\n",
    "        #print(epoch,loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step() # 更新学习率\n",
    "        train_losses.append(loss.item())# 记录训练损失\n",
    "        train.append(np.mean(train_losses))\n",
    "    #scheduler.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {np.mean(train_losses):.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "result_test = []\n",
    "lables_test = []\n",
    "GlycoproteinProphet.eval().to(device)\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, lables = data\n",
    "        lables = lables.float().to(device)\n",
    "        # print(glycan_X_train_tensor.shape)\n",
    "        outputs = GlycoproteinProphet(inputs).squeeze().to(device)\n",
    "        result_test.append(outputs.tolist())\n",
    "        lables_test.append(lables.tolist())\n",
    "my_result = [item for sublist in result_test for item in sublist]\n",
    "my_labels = [item for sublist in lables_test for item in sublist]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "my_test_pred_test = []\n",
    "for i in my_result:\n",
    "    if i > 0.5:\n",
    "        my_test_pred_test.append(1)\n",
    "    else:\n",
    "        my_test_pred_test.append(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
